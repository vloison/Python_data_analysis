{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1DR2t4TqnGGfI7nmzSePwj47aWwfeYWZa","timestamp":1701111102691}],"authorship_tag":"ABX9TyOxxZDB+BDPlSuiXiXuugFC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduction à la régression linéaire"],"metadata":{"id":"qbGElNG3TdMY"}},{"cell_type":"markdown","source":["Nous utilisons plusieurs bibliothèques pour cette session :\n","- NumPy pour les opérations numériques (voir session 2).\n","- Pandas pour la manipulation des données (voir session 3).\n","- Matplotlib pour la visualisation des données (voir session 4).\n","- Scikit-learn pour les tâches d'apprentissage automatique, y compris les modèles de régression linéaire."],"metadata":{"id":"pSGZGYceUNHQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"clxIEYM_TcSe"},"outputs":[],"source":["# Import des bibliothèques nécessaires\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","np.random.seed(42)"]},{"cell_type":"markdown","source":["# 1. Génération et visualisation des données\n"],"metadata":{"id":"JRMSdRHIUUIV"}},{"cell_type":"markdown","source":["**Exercice :** Générer un NumPy Array `X` de 100 éléments pris aléatoirement entre 0 et 1."],"metadata":{"id":"ACjoUmAxUlGM"}},{"cell_type":"code","source":["# A compléter"],"metadata":{"id":"xbM8Y1D1UjhQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Générons maintenant le vecteur `Y` : $Y = 4 + 3X + \\sigma$, où $\\sigma$ est du petit bruit."],"metadata":{"id":"MzCnaIKpVAgL"}},{"cell_type":"code","source":["# Génération de données d'exemple\n","y = 4 + 3 * X + 0.5 * np.random.randn(100, 1)"],"metadata":{"id":"bECn64vIVdqM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualisons maintenant les données générées. \\\\\n","**Exercice :** A l'aide de la librairie `matplotlib.pyplot`, affichez un nuage de points ayant `X` en abscisse, et `Y` en ordonnée."],"metadata":{"id":"u4s5sN9WVqq2"}},{"cell_type":"code","source":["# A compléter\n"],"metadata":{"id":"4hPA3-FHV7c_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Régression linéaire pour l'explication du phénomène"],"metadata":{"id":"YyaQq2T2Wa0w"}},{"cell_type":"markdown","source":["## 2.1 Régression linéaire simple\n","Générons et entraînons le modèle sur les données d'entraînement avec les fonctions `LinearRegression()` et `fit` de scikit-learn."],"metadata":{"id":"4MQH_6uhWedp"}},{"cell_type":"code","source":["# Génération et entraînement du modèle\n","lin_reg = LinearRegression()\n","lin_reg.fit(X, y)\n","y_pred = lin_reg.predict(X)"],"metadata":{"id":"Qc1RkamJWd0C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualisation du modèle de régression linéaire\n","plt.scatter(X, y)\n","plt.plot(X, y_pred, color='red', label='Prédictions de régression linéaire')\n","plt.title('Modèle de régression linéaire')\n","plt.xlabel('Investissements publicitaires (€)')\n","plt.ylabel(\"Chiffre d'affaire (€)\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"NXIGJYBt_nKx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluons maintenant la qualité de la régression linéaire en calculant le coefficient R², l'erreur quadratique moyenne, et l'erreur absolue moyenne, grâce aux fonctions correspondantes de scikit-learn."],"metadata":{"id":"gqd1xcQIWz3V"}},{"cell_type":"code","source":["# R²\n","r2_simple = lin_reg.score(X, y)  # X = données indépendantes, y = 'vraies' données dépendantes\n","print('Coefficient R²:', r2_simple)\n","# Erreur quadratique moyenne\n","mse_simple = mean_squared_error(y, y_pred)  # y = 'vraies' données dépendantes, y_pred = données prédites par le modèle\n","print('Erreur quadratique moyenne:', mse_simple)\n","# Erreur absolue moyenne\n","mae_simple = mean_absolute_error(y, y_pred)\n","print('Erreur absolue moyenne:', mae_simple)"],"metadata":{"id":"80Q8CsBGVpg1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercice :** A l'aide des métriques affichées ci-dessus et du cours, concluez quant à la qualité du modèle de régression linéaire pour ce jeu de données."],"metadata":{"id":"RV6Q-Q6iK7bi"}},{"cell_type":"markdown","source":["## 2.2 Régression linéaire Ridge\n"],"metadata":{"id":"FIcDnYCaLgDN"}},{"cell_type":"markdown","source":["La régression Ridge est un modèle de régression linéaire avec une régularisation L2. Le terme de régularisation aide à prévenir le surajustement en pénalisant les coefficients importants. \\\\\n","Le paramètre alpha contrôle la force de la régularisation : une valeur alpha plus élevée signifie une régularisation plus forte. \\\\\n","\\\n","Commençons par générer et entraîner le modèle, et générer ses prédictions."],"metadata":{"id":"ouVv4Oy0LoLv"}},{"cell_type":"code","source":["# Régression Ridge\n","ridge_reg = Ridge(alpha=1.0)  # Vous pouvez ajuster le paramètre alpha ici pour la force de régularisation\n","ridge_reg.fit(X, y)\n","\n","# Prédictions avec Ridge\n","y_pred_ridge = ridge_reg.predict(X)"],"metadata":{"id":"lnhJWAzHL8fz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercice :** Faire un graphe matplotlib pour visualiser les données, et le modèle Ridge."],"metadata":{"id":"GyIP6AgRMdo_"}},{"cell_type":"code","source":["# A compléter"],"metadata":{"id":"uxd1Ty6wMgXM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercice :** Calculer le coefficient R², l'erreur quadratique moyenne, et l'erreur absolue moyenne du modèle de Ridge."],"metadata":{"id":"GgKOalyvNCg1"}},{"cell_type":"code","source":["# A compléter"],"metadata":{"id":"G3CtugsKNO1_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Régression linéaire pour la prédiction de phénomène\n","Générons maintenant un nouvel ensemble suivant la même loi que X et y."],"metadata":{"id":"Ro1I0l2lPKbe"}},{"cell_type":"code","source":["X_test = 1 +  np.random.rand(100, 1)\n","y_test = 4 + 3 * X_test + 0.5 * np.random.randn(100, 1)"],"metadata":{"id":"2VlB6DgwSrqb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Exercice :** Visualiser ce nouveau jeu de données avec matplotlib."],"metadata":{"id":"-FGHDaf3S68l"}},{"cell_type":"code","source":["# A compléter"],"metadata":{"id":"PO0Uos87S6Y3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Testons maintenant nos deux modèles de régression déjà entraînés sur ce nouveau jeu de données."],"metadata":{"id":"dBPOCX5FTua9"}},{"cell_type":"markdown","source":["**Exercice :** Calculer et afficher dans un graphique matplotlib le jeu de données `X_test` `y_test`, et les valeurs prédites par le modèle de régression simple et le modèle de régression Ridge pour `X_test`. Vous prendrez soin d'attribuer des labels à vos tracés et des titres à vos axes."],"metadata":{"id":"SHlEQs0LUCC5"}},{"cell_type":"code","source":["# A compléter"],"metadata":{"id":"YhAw_OpvUBrL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculons maintenant la qualité des prédictions faites sur le jeu de données test. \\\\\n","\\\n","**Exercice :** Calculez le coefficient R², l'erreur quadratique moyenne, et l'erreur absolue moyenne du modèle de Ridge et du modèle simple sur le jeu de données test. Comparez les valeurs obtenues sur l'ensemble de test `X_test` `y_test` et l'ensemble d'entraînement `X`, `y`. Concluez sur le modèle qui performe le mieux ici."],"metadata":{"id":"I6u-yrmzVmmK"}},{"cell_type":"code","source":["# A compléter"],"metadata":{"id":"uFsw_S2ITuGB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Exercice supplémentaire (optionnel) :\n","Voici un nouveau jeu de données. Affichez-le, et entraînez une régression linéaire simple et une régression linéaire dessus. Evaluez la qualité des deux modèles, et concluez sur la pertinence de ces modèles pour l'étude de ce jeu de données.\n"],"metadata":{"id":"jCDNFyfRXlWA"}},{"cell_type":"code","source":["X_bonus = 10 * np.random.rand(1000, 1)\n","y_bonus = 10 * X_bonus + 50 * np.random.randn(1000, 1)\n","\n","# A compléter"],"metadata":{"id":"VxhB_ZiHXzMy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# A compléter"],"metadata":{"id":"zWl3gW7lYJgf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*Et c'est tout pour aujourd'hui !*"],"metadata":{"id":"qfe6OqZUa0G3"}},{"cell_type":"code","source":[],"metadata":{"id":"dYyr4uc9a2nB"},"execution_count":null,"outputs":[]}]}